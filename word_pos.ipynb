{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import textgrid\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "\n",
    "# UD 기반 17개 품사 + (대명사 1,2,3인칭) + 침묵(SIL) = 총 20개\n",
    "POS_LIST = [\n",
    "    \"ADJ\",       # 형용사\n",
    "    \"ADP\",       # 전치사/후치사\n",
    "    \"ADV\",       # 부사\n",
    "    \"AUX\",       # 조동사\n",
    "    \"CCONJ\",     # 등위접속사\n",
    "    \"DET\",       # 한정사\n",
    "    \"INTJ\",      # 감탄사\n",
    "    \"NOUN\",      # 명사\n",
    "    \"NUM\",       # 수사\n",
    "    \"PART\",      # 불변화사 등\n",
    "    \"PRON_1\",  # 1,2인칭 대명사\n",
    "    \"PRON_2\",\n",
    "    \"PRON_3\",    # 3인칭 대명사\n",
    "    \"PROPN\",     # 고유명사\n",
    "    \"PUNCT\",     # 구두점\n",
    "    \"SCONJ\",     # 종속접속사\n",
    "    \"SYM\",       # 기호\n",
    "    \"VERB\",      # 동사\n",
    "    \"X\",         # 기타/판단 불가\n",
    "    \"SIL\"        # 침묵\n",
    "]\n",
    "\n",
    "POS2IDX = {pos: i for i, pos in enumerate(POS_LIST)}\n",
    "\n",
    "# 1/2인칭 대명사 후보\n",
    "FIRST_PRONOUNS = {\n",
    "    \"i\", \"me\", \"myself\", \"we\", \"us\", \"our\", \"ourselves\",\"we're\"\n",
    "}\n",
    "SECOND_PRONOUNS = {\n",
    "\"you\", \"your\", \"yourself\", \"yourselves\",\"you're\"\n",
    "}\n",
    "\n",
    "# 3인칭 대명사 후보\n",
    "THIRD_PRONOUNS = {\n",
    "    \"he\", \"him\", \"his\", \"himself\",\n",
    "    \"she\", \"her\", \"hers\", \"herself\",\n",
    "    \"it\", \"itself\",\n",
    "    \"they\", \"them\", \"theirs\", \"themselves\",\n",
    "    \"he's\", \"she's\", \"it's\", \"they're\"\n",
    "}\n",
    "\n",
    "def normalize_pronoun(token: str) -> str:\n",
    "    t = token.lower().strip()\n",
    "    expansions = {\n",
    "        \"he's\": \"he\",\n",
    "        \"she's\": \"she\",\n",
    "        \"it's\": \"it\",\n",
    "        \"they're\": \"they\",\n",
    "        \"you're\": \"you\",\n",
    "        \"we're\": \"we\"\n",
    "    }\n",
    "    if t in expansions:\n",
    "        return expansions[t]\n",
    "    return t\n",
    "\n",
    "def map_pos(word_text: str, ner_tag: str) -> str:\n",
    "    \"\"\"\n",
    "    word, ner 정보를 바탕으로  품사 중 하나를 결정.\n",
    "    침묵이면 SIL, 대명사면 1/2/3인칭 분리.\n",
    "    \"\"\"\n",
    "    # 빈 문자열 -> 침묵\n",
    "    if not word_text.strip():\n",
    "        return \"SIL\"\n",
    "    \n",
    "    word_lower = normalize_pronoun(word_text.lower().strip())\n",
    "    pos_tag = ner_tag.upper()\n",
    "    \n",
    "    # 대명사 감별\n",
    "    if pos_tag == \"PRON\":\n",
    "        if word_lower in FIRST_PRONOUNS:\n",
    "            return \"PRON_1\"\n",
    "        elif word_lower in SECOND_PRONOUNS:\n",
    "            return \"PRON_2\"\n",
    "        elif word_lower in THIRD_PRONOUNS:\n",
    "            return \"PRON_3\"\n",
    "        else:\n",
    "            # 기타 대명사는 3인칭으로 처리(정책에 따라 조정)\n",
    "            return \"PRON_3\"\n",
    "    \n",
    "    # POS_LIST 중 매칭\n",
    "    for pos_candidate in POS_LIST:\n",
    "        if pos_candidate.upper() == pos_tag:\n",
    "            return pos_candidate\n",
    "    return \"X\"\n",
    "\n",
    "def get_intervals_including_silence(tier: textgrid.IntervalTier, global_min: float, global_max: float):\n",
    "    intervals = sorted(tier.intervals, key=lambda x: x.minTime)\n",
    "    merged = []\n",
    "\n",
    "    if not intervals:\n",
    "        # 해당 tier에 interval이 하나도 없으면 전체 구간을 침묵 처리\n",
    "        merged.append((global_min, global_max, \"\"))\n",
    "        return merged\n",
    "\n",
    "    # 맨 앞 침묵\n",
    "    if intervals[0].minTime > global_min:\n",
    "        merged.append((global_min, intervals[0].minTime, \"\"))  # 침묵\n",
    "\n",
    "    # 중간 병합\n",
    "    for i in range(len(intervals)):\n",
    "        current = intervals[i]\n",
    "        merged.append((current.minTime, current.maxTime, current.mark))\n",
    "        \n",
    "        # 다음 interval과 gap\n",
    "        if i < len(intervals) - 1:\n",
    "            nxt = intervals[i+1]\n",
    "            if current.maxTime < nxt.minTime:\n",
    "                # 침묵\n",
    "                merged.append((current.maxTime, nxt.minTime, \"\"))\n",
    "\n",
    "    # 맨 뒤 침묵\n",
    "    if intervals[-1].maxTime < global_max:\n",
    "        merged.append((intervals[-1].maxTime, global_max, \"\"))\n",
    "\n",
    "    return merged\n",
    "\n",
    "def process_textgrid_filelevel(textgrid_path: str, wav_path: str) -> torch.Tensor:\n",
    "    tg = textgrid.TextGrid.fromFile(textgrid_path)\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "    duration_sec = len(audio) / 1000.0\n",
    "    if duration_sec == 0.0:\n",
    "        duration_sec = 1e-6\n",
    "\n",
    "    global_min = tg.minTime\n",
    "    global_max = tg.maxTime\n",
    "\n",
    "    word_tier = tg[0]\n",
    "    ner_tier  = tg[1]\n",
    "\n",
    "    w_intervals = get_intervals_including_silence(word_tier, global_min, global_max)\n",
    "    n_intervals = get_intervals_including_silence(ner_tier,  global_min, global_max)\n",
    "\n",
    "    count_pos = [0]*len(POS_LIST)\n",
    "    total_words = 0\n",
    "    \n",
    "    for (w_start, w_end, w_text), (_, _, ner_tag) in zip(w_intervals, n_intervals):\n",
    "        final_pos = map_pos(w_text, ner_tag)\n",
    "        count_pos[POS2IDX[final_pos]] += 1\n",
    "        \n",
    "        if final_pos != \"SIL\":\n",
    "            total_words += 1\n",
    "\n",
    "    if total_words == 0:\n",
    "        total_words = 1e-6\n",
    "\n",
    "    vec_per_word = [c / total_words for c in count_pos]\n",
    "    vec_per_sec  = [c / duration_sec  for c in count_pos]\n",
    "\n",
    "    final_vec = vec_per_word + vec_per_sec  # 38차원\n",
    "    return torch.tensor(final_vec, dtype=torch.float)\n",
    "\n",
    "def process_textgrid_wordlevel(textgrid_path: str, wav_path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    (단어/interval 단위) : 하나의 TextGrid에 대해\n",
    "    침묵 구간 포함 N개의 interval 각각을 19차원 원-핫 인코딩으로 만들어\n",
    "    최종 (N x 19) 텐서를 반환.\n",
    "    \"\"\"\n",
    "    tg = textgrid.TextGrid.fromFile(textgrid_path)\n",
    "    global_min = tg.minTime\n",
    "    global_max = tg.maxTime\n",
    "    \n",
    "    word_tier = tg[0]\n",
    "    ner_tier  = tg[1]\n",
    "\n",
    "    w_intervals = get_intervals_including_silence(word_tier, global_min, global_max)\n",
    "    n_intervals = get_intervals_including_silence(ner_tier,  global_min, global_max)\n",
    "\n",
    "    # 각 interval마다 19차원 원-핫\n",
    "    one_hot_list = []\n",
    "\n",
    "    for (w_start, w_end, w_text), (_, _, ner_tag) in zip(w_intervals, n_intervals):\n",
    "        final_pos = map_pos(w_text, ner_tag)\n",
    "        \n",
    "        # 19차원 중 해당 품사만 1, 나머지는 0\n",
    "        vec = [0]*len(POS_LIST)\n",
    "        pos_idx = POS2IDX[final_pos]\n",
    "        vec[pos_idx] = 1\n",
    "        \n",
    "        one_hot_list.append(vec)\n",
    "\n",
    "    return torch.tensor(one_hot_list, dtype=torch.float)  # (N x 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data_38 = {}        # 파일 단위 38차원\n",
    "all_data_wordlevel = {} # (N x 19) 단어 단위\n",
    "\n",
    "# Audios/*.wav 전부 순회\n",
    "for wav_file in tqdm(glob.glob(\"Audios/*.wav\"), desc=\"Processing WAV files\"):\n",
    "    base_name = os.path.splitext(os.path.basename(wav_file))[0]\n",
    "    tgrid_path = os.path.join(\"result_nertg\", base_name + \".TextGrid\")\n",
    "    \n",
    "    if os.path.exists(tgrid_path):\n",
    "        # TextGrid와 WAV 파일이 모두 존재하는 경우\n",
    "        \n",
    "        # (1) 파일 단위 38차원\n",
    "        feature_38 = process_textgrid_filelevel(tgrid_path, wav_file)\n",
    "        all_data_38[base_name] = feature_38\n",
    "        \n",
    "        # (2) 단어 단위 Nx19\n",
    "        word_tensor = process_textgrid_wordlevel(tgrid_path, wav_file)\n",
    "        all_data_wordlevel[base_name] = word_tensor\n",
    "    \n",
    "    else:\n",
    "        # TextGrid 없으면 모두 0으로 처리\n",
    "        # 38차원 0벡터\n",
    "        all_data_38[base_name] = torch.zeros(40, dtype=torch.float)\n",
    "        # 단어 단위: 구간 자체가 없으니 (1 x 19) 또는 (0 x 19) 중 선택 가능\n",
    "        # 여기서는 (0 x 19) 텐서로 처리\n",
    "        all_data_wordlevel[base_name] = torch.zeros(0, 20, dtype=torch.float)\n",
    "\n",
    "# 결과 저장\n",
    "torch.save(all_data_38, \"sentence_pos.pt\")\n",
    "torch.save(all_data_wordlevel, \"word_pos.pt\")\n",
    "\n",
    "print(\"Saved sentence_pos.pt and word_pos.pt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
